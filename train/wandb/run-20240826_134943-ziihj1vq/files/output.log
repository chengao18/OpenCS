  0%|                                                                                                                                               | 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 8.583, 'grad_norm': 448.76290023240557, 'learning_rate': 1.8666666666666667e-06, 'epoch': 0.56}
  7%|█████████                                                                                                                              | 1/15 [00:42<10:00, 42.93s/it]

 13%|██████████████████                                                                                                                     | 2/15 [01:21<08:45, 40.39s/it]

 20%|███████████████████████████                                                                                                            | 3/15 [02:00<07:54, 39.58s/it]

 27%|████████████████████████████████████                                                                                                   | 4/15 [02:38<07:10, 39.17s/it]


 40%|██████████████████████████████████████████████████████                                                                                 | 6/15 [03:55<05:48, 38.71s/it]
{'loss': 5.7488, 'grad_norm': 81.75012244352452, 'learning_rate': 1.2e-06, 'epoch': 3.37}

 47%|███████████████████████████████████████████████████████████████                                                                        | 7/15 [04:33<05:08, 38.62s/it]

 53%|████████████████████████████████████████████████████████████████████████                                                               | 8/15 [05:12<04:29, 38.56s/it]

 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 9/15 [05:50<03:51, 38.56s/it]


 73%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 11/15 [07:07<02:33, 38.41s/it]
{'loss': 5.0889, 'grad_norm': 68.79425777158839, 'learning_rate': 5.333333333333333e-07, 'epoch': 6.18}

 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                          | 12/15 [07:45<01:55, 38.40s/it]

 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 13/15 [08:24<01:16, 38.45s/it]

 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 14/15 [09:02<00:38, 38.46s/it]
{'loss': 4.9952, 'grad_norm': 55.9967040045662, 'learning_rate': 0.0, 'epoch': 8.42}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [09:41<00:00, 38.41s/it][INFO|trainer.py:2383] 2024-08-26 13:59:31,999 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [09:41<00:00, 38.74s/it]
[INFO|trainer.py:3478] 2024-08-26 13:59:39,728 >> Saving model checkpoint to /model/output/mistral-7b-my_prompt_1000_trans_sharegpt-e15lr2e-06-8gpus
[INFO|configuration_utils.py:472] 2024-08-26 13:59:39,730 >> Configuration saved in /model/output/mistral-7b-my_prompt_1000_trans_sharegpt-e15lr2e-06-8gpus/config.json
[INFO|configuration_utils.py:769] 2024-08-26 13:59:39,731 >> Configuration saved in /model/output/mistral-7b-my_prompt_1000_trans_sharegpt-e15lr2e-06-8gpus/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-26 13:59:54,505 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/mistral-7b-my_prompt_1000_trans_sharegpt-e15lr2e-06-8gpus/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-26 13:59:54,506 >> tokenizer config file saved in /model/output/mistral-7b-my_prompt_1000_trans_sharegpt-e15lr2e-06-8gpus/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-26 13:59:54,506 >> Special tokens file saved in /model/output/mistral-7b-my_prompt_1000_trans_sharegpt-e15lr2e-06-8gpus/special_tokens_map.json
***** train metrics *****
  epoch                    =     8.4211
  total_flos               =     1543GF
  train_loss               =      5.844
  train_runtime            = 0:09:50.22
  train_samples_per_second =     22.873
  train_steps_per_second   =      0.025
Figure saved at: /model/output/mistral-7b-my_prompt_1000_trans_sharegpt-e15lr2e-06-8gpus/training_loss.png
08/26/2024 13:59:55 - WARNING - llamafactory.extras.ploting - No metric eval_loss to plot.
[INFO|trainer.py:3788] 2024-08-26 13:59:55,190 >>
***** Running Evaluation *****
[INFO|trainer.py:3790] 2024-08-26 13:59:55,190 >>   Num examples = 100
[INFO|trainer.py:3793] 2024-08-26 13:59:55,190 >>   Batch size = 1

 69%|█████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 9/13 [00:02<00:01,  3.09it/s]
***** eval metrics *****
  epoch                   =     8.4211
  eval_loss               =     1.7098
  eval_runtime            = 0:00:04.60
  eval_samples_per_second =     21.728
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:04<00:00,  3.09it/s]
[INFO|modelcard.py:449] 2024-08-26 13:59:59,793 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}