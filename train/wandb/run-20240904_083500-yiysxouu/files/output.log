  0%|                                                                                                                                                     | 0/45 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  2%|███▏                                                                                                                                         | 1/45 [00:25<18:38, 25.41s/it]

  4%|██████▎                                                                                                                                      | 2/45 [00:45<16:10, 22.56s/it]

  7%|█████████▍                                                                                                                                   | 3/45 [01:06<15:05, 21.55s/it]

  9%|████████████▌                                                                                                                                | 4/45 [01:26<14:27, 21.16s/it]
{'loss': 1.1015, 'grad_norm': 7.975449801110235, 'learning_rate': 9.111111111111112e-06, 'epoch': 1.12}


 13%|██████████████████▊                                                                                                                          | 6/45 [02:07<13:28, 20.74s/it]

 16%|█████████████████████▉                                                                                                                       | 7/45 [02:28<13:11, 20.82s/it]

 18%|█████████████████████████                                                                                                                    | 8/45 [02:49<12:53, 20.90s/it]

 20%|████████████████████████████▏                                                                                                                | 9/45 [03:10<12:34, 20.95s/it]

 22%|███████████████████████████████                                                                                                             | 10/45 [03:31<12:14, 20.98s/it]

 24%|██████████████████████████████████▏                                                                                                         | 11/45 [03:52<11:53, 21.00s/it]

 27%|█████████████████████████████████████▎                                                                                                      | 12/45 [04:13<11:32, 20.99s/it]

 29%|████████████████████████████████████████▍                                                                                                   | 13/45 [04:34<11:12, 21.00s/it]

 31%|███████████████████████████████████████████▌                                                                                                | 14/45 [04:55<10:49, 20.95s/it]

 33%|██████████████████████████████████████████████▋                                                                                             | 15/45 [05:16<10:25, 20.84s/it]

 36%|█████████████████████████████████████████████████▊                                                                                          | 16/45 [05:37<10:06, 20.90s/it]

 38%|████████████████████████████████████████████████████▉                                                                                       | 17/45 [05:58<09:46, 20.95s/it]

 40%|████████████████████████████████████████████████████████                                                                                    | 18/45 [06:19<09:26, 20.97s/it]

 42%|███████████████████████████████████████████████████████████                                                                                 | 19/45 [06:40<09:05, 20.98s/it]

 44%|██████████████████████████████████████████████████████████████▏                                                                             | 20/45 [07:01<08:44, 20.97s/it]

 47%|█████████████████████████████████████████████████████████████████▎                                                                          | 21/45 [07:21<08:19, 20.82s/it]

 49%|████████████████████████████████████████████████████████████████████▍                                                                       | 22/45 [07:42<07:56, 20.72s/it]

 51%|███████████████████████████████████████████████████████████████████████▌                                                                    | 23/45 [08:03<07:35, 20.71s/it]

 53%|██████████████████████████████████████████████████████████████████████████▋                                                                 | 24/45 [08:23<07:13, 20.64s/it]

 56%|█████████████████████████████████████████████████████████████████████████████▊                                                              | 25/45 [08:44<06:52, 20.64s/it]

 58%|████████████████████████████████████████████████████████████████████████████████▉                                                           | 26/45 [09:04<06:31, 20.60s/it]

 60%|████████████████████████████████████████████████████████████████████████████████████                                                        | 27/45 [09:25<06:10, 20.56s/it]

 62%|███████████████████████████████████████████████████████████████████████████████████████                                                     | 28/45 [09:45<05:48, 20.52s/it]

 64%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 29/45 [10:06<05:28, 20.50s/it]

 67%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 30/45 [10:26<05:07, 20.47s/it]

 69%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 31/45 [10:46<04:46, 20.47s/it]

 71%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 32/45 [11:07<04:26, 20.48s/it]

 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 33/45 [11:27<04:06, 20.50s/it]

 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 34/45 [11:48<03:45, 20.53s/it]

 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                               | 35/45 [12:09<03:25, 20.53s/it]

 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 36/45 [12:29<03:04, 20.52s/it]

 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                         | 37/45 [12:50<02:44, 20.52s/it]

 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 38/45 [13:10<02:23, 20.52s/it]

 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 39/45 [13:31<02:03, 20.51s/it]

 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 40/45 [13:51<01:42, 20.46s/it]

 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌            | 41/45 [14:12<01:21, 20.49s/it]

 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 42/45 [14:32<01:01, 20.51s/it]

 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 43/45 [14:53<00:41, 20.52s/it]

 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 44/45 [15:13<00:20, 20.49s/it]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [15:34<00:00, 20.51s/it][INFO|trainer.py:2383] 2024-09-04 08:50:41,443 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [15:34<00:00, 20.76s/it]
{'loss': 0.0487, 'grad_norm': 5.685392890713652, 'learning_rate': 0.0, 'epoch': 12.63}
{'train_runtime': 944.6564, 'train_samples_per_second': 14.275, 'train_steps_per_second': 0.048, 'train_loss': 0.35955885946750643, 'epoch': 12.63}
[INFO|trainer.py:3478] 2024-09-04 08:50:48,479 >> Saving model checkpoint to /model/output/llama2-7b-alpaca_tips_wo_pair_score_1k_sharegpt-e15lr1e-05
[INFO|configuration_utils.py:472] 2024-09-04 08:50:48,483 >> Configuration saved in /model/output/llama2-7b-alpaca_tips_wo_pair_score_1k_sharegpt-e15lr1e-05/config.json
[INFO|configuration_utils.py:769] 2024-09-04 08:50:48,483 >> Configuration saved in /model/output/llama2-7b-alpaca_tips_wo_pair_score_1k_sharegpt-e15lr1e-05/generation_config.json
[INFO|modeling_utils.py:2698] 2024-09-04 08:51:02,574 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/llama2-7b-alpaca_tips_wo_pair_score_1k_sharegpt-e15lr1e-05/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-09-04 08:51:02,574 >> tokenizer config file saved in /model/output/llama2-7b-alpaca_tips_wo_pair_score_1k_sharegpt-e15lr1e-05/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-09-04 08:51:02,575 >> Special tokens file saved in /model/output/llama2-7b-alpaca_tips_wo_pair_score_1k_sharegpt-e15lr1e-05/special_tokens_map.json
[INFO|trainer.py:3788] 2024-09-04 08:51:03,268 >>
***** Running Evaluation *****
[INFO|trainer.py:3790] 2024-09-04 08:51:03,268 >>   Num examples = 100
[INFO|trainer.py:3793] 2024-09-04 08:51:03,268 >>   Batch size = 1
 46%|█████████████████████████████████████████████████████████████████                                                                            | 6/13 [00:01<00:02,  3.24it/s]
***** train metrics *****
  epoch                    =    12.6316
  total_flos               =     1910GF
  train_loss               =     0.3596
  train_runtime            = 0:15:44.65
  train_samples_per_second =     14.275
  train_steps_per_second   =      0.048
Figure saved at: /model/output/llama2-7b-alpaca_tips_wo_pair_score_1k_sharegpt-e15lr1e-05/training_loss.png
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:04<00:00,  3.21it/s]
[INFO|modelcard.py:449] 2024-09-04 08:51:07,692 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
***** eval metrics *****
  epoch                   =    12.6316
  eval_loss               =     1.3221
  eval_runtime            = 0:00:04.42
  eval_samples_per_second =     22.605
  eval_steps_per_second   =      2.939