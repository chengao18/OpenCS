  0%|                                                                                                      | 0/135 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  1%|▋                                                                                           | 1/135 [00:52<1:56:26, 52.14s/it]

  1%|█▎                                                                                          | 2/135 [01:41<1:51:59, 50.52s/it]

  2%|██                                                                                          | 3/135 [02:30<1:49:47, 49.91s/it]
{'loss': 0.9196, 'grad_norm': 10.039408660739149, 'learning_rate': 2.9268292682926825e-07, 'epoch': 0.07}


  4%|███▍                                                                                        | 5/135 [04:09<1:47:14, 49.50s/it]
{'loss': 0.8968, 'grad_norm': 9.136487027443136, 'learning_rate': 4.878048780487804e-07, 'epoch': 0.11}


  5%|████▊                                                                                       | 7/135 [05:47<1:45:07, 49.28s/it]

  6%|█████▍                                                                                      | 8/135 [06:36<1:44:21, 49.30s/it]
{'loss': 0.8507, 'grad_norm': 5.162546093898906, 'learning_rate': 7.804878048780488e-07, 'epoch': 0.17}


  7%|██████▋                                                                                    | 10/135 [08:14<1:42:31, 49.21s/it]
{'loss': 0.8711, 'grad_norm': 4.825435543661852, 'learning_rate': 9.756097560975609e-07, 'epoch': 0.22}


  9%|████████                                                                                   | 12/135 [09:53<1:40:50, 49.19s/it]
{'loss': 0.8066, 'grad_norm': 5.324480975292333, 'learning_rate': 1.170731707317073e-06, 'epoch': 0.26}


 10%|█████████▍                                                                                 | 14/135 [11:31<1:39:03, 49.12s/it]
{'loss': 0.8206, 'grad_norm': 3.351800229904665, 'learning_rate': 1.3658536585365854e-06, 'epoch': 0.31}


 12%|██████████▊                                                                                | 16/135 [13:09<1:37:13, 49.02s/it]
{'loss': 0.7946, 'grad_norm': 3.5211819959525816, 'learning_rate': 1.5609756097560975e-06, 'epoch': 0.35}


 13%|████████████▏                                                                              | 18/135 [14:47<1:35:37, 49.04s/it]
{'loss': 0.8087, 'grad_norm': 2.9481170011100115, 'learning_rate': 1.7560975609756096e-06, 'epoch': 0.39}


 15%|█████████████▍                                                                             | 20/135 [16:25<1:34:00, 49.05s/it]
{'loss': 0.7786, 'grad_norm': 2.781540673314605, 'learning_rate': 1.9512195121951218e-06, 'epoch': 0.44}


 16%|██████████████▊                                                                            | 22/135 [18:03<1:32:23, 49.06s/it]
{'loss': 0.7668, 'grad_norm': 2.311308167026337, 'learning_rate': 2.1463414634146343e-06, 'epoch': 0.48}


 18%|████████████████▏                                                                          | 24/135 [19:42<1:30:56, 49.16s/it]
{'loss': 0.7431, 'grad_norm': 2.185974570144763, 'learning_rate': 2.341463414634146e-06, 'epoch': 0.52}


 19%|█████████████████▌                                                                         | 26/135 [21:20<1:29:14, 49.13s/it]
{'loss': 0.7489, 'grad_norm': 2.1529055102884724, 'learning_rate': 2.5365853658536586e-06, 'epoch': 0.57}


 21%|██████████████████▊                                                                        | 28/135 [22:58<1:27:42, 49.18s/it]

 21%|███████████████████▌                                                                       | 29/135 [23:47<1:26:52, 49.17s/it]
{'loss': 0.6986, 'grad_norm': 2.297826038094001, 'learning_rate': 2.8292682926829266e-06, 'epoch': 0.63}


 23%|████████████████████▉                                                                      | 31/135 [25:26<1:25:07, 49.11s/it]
{'loss': 0.7624, 'grad_norm': 2.3838319692536003, 'learning_rate': 3.0243902439024387e-06, 'epoch': 0.68}


 24%|██████████████████████▏                                                                    | 33/135 [27:04<1:23:28, 49.11s/it]

 25%|██████████████████████▉                                                                    | 34/135 [27:52<1:22:26, 48.97s/it]

 26%|███████████████████████▌                                                                   | 35/135 [28:42<1:21:45, 49.05s/it]
{'loss': 0.734, 'grad_norm': 2.030630163841926, 'learning_rate': 3.414634146341463e-06, 'epoch': 0.77}


 27%|████████████████████████▉                                                                  | 37/135 [30:20<1:20:20, 49.19s/it]

 28%|█████████████████████████▌                                                                 | 38/135 [31:10<1:19:36, 49.24s/it]

 29%|██████████████████████████▎                                                                | 39/135 [31:59<1:18:45, 49.23s/it]

 30%|██████████████████████████▉                                                                | 40/135 [32:48<1:17:54, 49.20s/it]
{'loss': 0.7085, 'grad_norm': 2.0855448492582993, 'learning_rate': 3.9024390243902435e-06, 'epoch': 0.87}


 31%|████████████████████████████▎                                                              | 42/135 [34:26<1:16:14, 49.19s/it]
{'loss': 0.7085, 'grad_norm': 2.4516513553074706, 'learning_rate': 3.998883127460509e-06, 'epoch': 0.92}


 33%|█████████████████████████████▋                                                             | 44/135 [36:05<1:14:37, 49.20s/it]

 33%|██████████████████████████████▎                                                            | 45/135 [36:54<1:13:46, 49.18s/it]

 34%|███████████████████████████████                                                            | 46/135 [37:43<1:12:59, 49.21s/it]

 35%|███████████████████████████████▋                                                           | 47/135 [38:32<1:12:08, 49.19s/it]
{'loss': 0.6377, 'grad_norm': 3.5721938103600164, 'learning_rate': 3.9599234100731735e-06, 'epoch': 1.03}


 36%|█████████████████████████████████                                                          | 49/135 [40:11<1:10:29, 49.18s/it]
{'loss': 0.6192, 'grad_norm': 3.2066831597309164, 'learning_rate': 3.928938350108753e-06, 'epoch': 1.07}


 38%|██████████████████████████████████▍                                                        | 51/135 [41:50<1:09:00, 49.29s/it]

 39%|███████████████████████████████████                                                        | 52/135 [42:39<1:08:09, 49.27s/it]
{'loss': 0.6075, 'grad_norm': 2.6571798155744264, 'learning_rate': 3.866361222083205e-06, 'epoch': 1.14}


 40%|████████████████████████████████████▍                                                      | 54/135 [44:17<1:06:26, 49.21s/it]
{'loss': 0.6036, 'grad_norm': 2.4978671512569215, 'learning_rate': 3.8141818274686816e-06, 'epoch': 1.18}


 41%|█████████████████████████████████████▋                                                     | 56/135 [45:55<1:04:41, 49.13s/it]
{'loss': 0.6401, 'grad_norm': 2.346186376083968, 'learning_rate': 3.753899856413343e-06, 'epoch': 1.22}


 43%|███████████████████████████████████████                                                    | 58/135 [47:33<1:03:03, 49.13s/it]
{'loss': 0.6153, 'grad_norm': 2.257890957323846, 'learning_rate': 3.685784542833594e-06, 'epoch': 1.27}


 44%|████████████████████████████████████████▍                                                  | 60/135 [49:12<1:01:32, 49.24s/it]

 45%|█████████████████████████████████████████                                                  | 61/135 [50:01<1:00:40, 49.19s/it]

 46%|██████████████████████████████████████████▋                                                  | 62/135 [50:50<59:47, 49.14s/it]

 47%|███████████████████████████████████████████▍                                                 | 63/135 [51:39<58:51, 49.05s/it]

 47%|████████████████████████████████████████████                                                 | 64/135 [52:28<58:07, 49.12s/it]

 48%|████████████████████████████████████████████▊                                                | 65/135 [53:17<57:19, 49.13s/it]
{'loss': 0.5933, 'grad_norm': 2.1552627072328607, 'learning_rate': 3.3903848553492846e-06, 'epoch': 1.42}


 50%|██████████████████████████████████████████████▏                                              | 67/135 [54:55<55:37, 49.08s/it]
{'loss': 0.6278, 'grad_norm': 2.079564105356248, 'learning_rate': 3.2912557031176047e-06, 'epoch': 1.46}


 51%|███████████████████████████████████████████████▌                                             | 69/135 [56:34<54:03, 49.15s/it]
{'loss': 0.6349, 'grad_norm': 2.195112008819187, 'learning_rate': 3.1863594894587103e-06, 'epoch': 1.51}


 53%|████████████████████████████████████████████████▉                                            | 71/135 [58:12<52:27, 49.18s/it]
{'loss': 0.5887, 'grad_norm': 2.15887402079387, 'learning_rate': 3.0761647063267455e-06, 'epoch': 1.55}


 54%|██████████████████████████████████████████████████▎                                          | 73/135 [59:50<50:43, 49.09s/it]

 55%|█████████████████████████████████████████████████▉                                         | 74/135 [1:00:39<49:56, 49.12s/it]

 56%|██████████████████████████████████████████████████▌                                        | 75/135 [1:01:29<49:07, 49.13s/it]

 56%|███████████████████████████████████████████████████▏                                       | 76/135 [1:02:18<48:20, 49.17s/it]

 57%|███████████████████████████████████████████████████▉                                       | 77/135 [1:03:07<47:30, 49.15s/it]

 58%|████████████████████████████████████████████████████▌                                      | 78/135 [1:03:56<46:36, 49.06s/it]

 59%|█████████████████████████████████████████████████████▎                                     | 79/135 [1:04:45<45:49, 49.09s/it]

 59%|█████████████████████████████████████████████████████▉                                     | 80/135 [1:05:34<45:00, 49.09s/it]

 60%|██████████████████████████████████████████████████████▌                                    | 81/135 [1:06:23<44:07, 49.03s/it]

 61%|███████████████████████████████████████████████████████▎                                   | 82/135 [1:07:12<43:17, 49.01s/it]

 61%|███████████████████████████████████████████████████████▉                                   | 83/135 [1:08:01<42:30, 49.05s/it]
{'loss': 0.5747, 'grad_norm': 2.1273486677737066, 'learning_rate': 2.33265870916626e-06, 'epoch': 1.81}


 63%|█████████████████████████████████████████████████████████▎                                 | 85/135 [1:09:39<40:52, 49.05s/it]

 64%|█████████████████████████████████████████████████████████▉                                 | 86/135 [1:10:28<40:05, 49.09s/it]

 64%|██████████████████████████████████████████████████████████▋                                | 87/135 [1:11:17<39:15, 49.07s/it]

 65%|███████████████████████████████████████████████████████████▎                               | 88/135 [1:12:07<38:31, 49.17s/it]

 66%|███████████████████████████████████████████████████████████▉                               | 89/135 [1:12:56<37:46, 49.28s/it]

 67%|████████████████████████████████████████████████████████████▋                              | 90/135 [1:13:45<36:55, 49.22s/it]

 67%|█████████████████████████████████████████████████████████████▎                             | 91/135 [1:14:34<36:02, 49.15s/it]

 68%|██████████████████████████████████████████████████████████████                             | 92/135 [1:15:23<35:11, 49.11s/it]
{'loss': 0.5148, 'grad_norm': 3.4154073829116722, 'learning_rate': 1.7334260892524428e-06, 'epoch': 2.01}


 70%|███████████████████████████████████████████████████████████████▎                           | 94/135 [1:17:02<33:34, 49.13s/it]

 70%|████████████████████████████████████████████████████████████████                           | 95/135 [1:17:50<32:43, 49.08s/it]

 71%|████████████████████████████████████████████████████████████████▋                          | 96/135 [1:18:40<31:54, 49.08s/it]

 72%|█████████████████████████████████████████████████████████████████▍                         | 97/135 [1:19:29<31:04, 49.06s/it]

 73%|██████████████████████████████████████████████████████████████████                         | 98/135 [1:20:18<30:17, 49.11s/it]

 73%|██████████████████████████████████████████████████████████████████▋                        | 99/135 [1:21:07<29:30, 49.17s/it]

 74%|██████████████████████████████████████████████████████████████████▋                       | 100/135 [1:21:56<28:38, 49.11s/it]

 75%|███████████████████████████████████████████████████████████████████▎                      | 101/135 [1:22:45<27:50, 49.14s/it]
{'loss': 0.4582, 'grad_norm': 3.09418230215311, 'learning_rate': 1.1581304751433303e-06, 'epoch': 2.21}


 76%|████████████████████████████████████████████████████████████████████▋                     | 103/135 [1:24:24<26:12, 49.15s/it]
{'loss': 0.4437, 'grad_norm': 2.4252316747684226, 'learning_rate': 1.0388364896266325e-06, 'epoch': 2.25}


 78%|██████████████████████████████████████████████████████████████████████                    | 105/135 [1:26:01<24:29, 48.99s/it]

 79%|██████████████████████████████████████████████████████████████████████▋                   | 106/135 [1:26:50<23:39, 48.96s/it]

 79%|███████████████████████████████████████████████████████████████████████▎                  | 107/135 [1:27:40<22:53, 49.04s/it]
{'loss': 0.4668, 'grad_norm': 2.331844558782957, 'learning_rate': 8.136405105412895e-07, 'epoch': 2.34}


 81%|████████████████████████████████████████████████████████████████████████▋                 | 109/135 [1:29:18<21:18, 49.18s/it]

 81%|█████████████████████████████████████████████████████████████████████████▎                | 110/135 [1:30:07<20:28, 49.14s/it]

 82%|██████████████████████████████████████████████████████████████████████████                | 111/135 [1:30:56<19:39, 49.17s/it]

 83%|██████████████████████████████████████████████████████████████████████████▋               | 112/135 [1:31:46<18:51, 49.18s/it]

 84%|███████████████████████████████████████████████████████████████████████████▎              | 113/135 [1:32:34<17:59, 49.05s/it]
{'loss': 0.4724, 'grad_norm': 2.053750292173749, 'learning_rate': 5.166957887040848e-07, 'epoch': 2.47}


 85%|████████████████████████████████████████████████████████████████████████████▋             | 115/135 [1:34:13<16:21, 49.08s/it]

 86%|█████████████████████████████████████████████████████████████████████████████▎            | 116/135 [1:35:02<15:33, 49.12s/it]
{'loss': 0.4511, 'grad_norm': 2.047420050582047, 'learning_rate': 3.8985989374487427e-07, 'epoch': 2.54}


 87%|██████████████████████████████████████████████████████████████████████████████▋           | 118/135 [1:36:40<13:55, 49.16s/it]

 88%|███████████████████████████████████████████████████████████████████████████████▎          | 119/135 [1:37:29<13:07, 49.19s/it]

 89%|████████████████████████████████████████████████████████████████████████████████          | 120/135 [1:38:18<12:16, 49.11s/it]
{'loss': 0.4523, 'grad_norm': 1.971254118610886, 'learning_rate': 2.46100143586657e-07, 'epoch': 2.62}


 90%|█████████████████████████████████████████████████████████████████████████████████▎        | 122/135 [1:39:57<10:39, 49.19s/it]

 91%|██████████████████████████████████████████████████████████████████████████████████        | 123/135 [1:40:46<09:50, 49.18s/it]
{'loss': 0.4301, 'grad_norm': 1.8384351906639533, 'learning_rate': 1.587002266471422e-07, 'epoch': 2.69}


 93%|███████████████████████████████████████████████████████████████████████████████████▎      | 125/135 [1:42:25<08:12, 49.22s/it]
{'loss': 0.4388, 'grad_norm': 1.8744330502711295, 'learning_rate': 1.1066181678416264e-07, 'epoch': 2.73}


 94%|████████████████████████████████████████████████████████████████████████████████████▋     | 127/135 [1:44:03<06:32, 49.11s/it]
{'loss': 0.4514, 'grad_norm': 1.9570783354373447, 'learning_rate': 7.106164989124708e-08, 'epoch': 2.78}


 96%|██████████████████████████████████████████████████████████████████████████████████████    | 129/135 [1:45:41<04:54, 49.11s/it]
{'loss': 0.4611, 'grad_norm': 1.9417808984817881, 'learning_rate': 4.00765899268265e-08, 'epoch': 2.82}


 97%|███████████████████████████████████████████████████████████████████████████████████████▎  | 131/135 [1:47:19<03:16, 49.13s/it]

 98%|████████████████████████████████████████████████████████████████████████████████████████  | 132/135 [1:48:08<02:27, 49.15s/it]

 99%|████████████████████████████████████████████████████████████████████████████████████████▋ | 133/135 [1:48:57<01:38, 49.08s/it]

 99%|█████████████████████████████████████████████████████████████████████████████████████████▎| 134/135 [1:49:46<00:49, 49.09s/it]
100%|██████████████████████████████████████████████████████████████████████████████████████████| 135/135 [1:50:36<00:00, 49.12s/it][INFO|trainer.py:2383] 2024-08-27 03:57:48,086 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|██████████████████████████████████████████████████████████████████████████████████████████| 135/135 [1:50:36<00:00, 49.16s/it]
{'loss': 0.4761, 'grad_norm': 1.9411530665399437, 'learning_rate': 0.0, 'epoch': 2.95}
{'train_runtime': 6645.1156, 'train_samples_per_second': 21.128, 'train_steps_per_second': 0.02, 'train_loss': 0.6191861757525692, 'epoch': 2.95}
[INFO|trainer.py:3478] 2024-08-27 03:57:56,035 >> Saving model checkpoint to /model/output/mistral-7b-fastchat_evol_instruct_70k_beautified-e3lr4e-06
[INFO|configuration_utils.py:472] 2024-08-27 03:57:56,038 >> Configuration saved in /model/output/mistral-7b-fastchat_evol_instruct_70k_beautified-e3lr4e-06/config.json
[INFO|configuration_utils.py:769] 2024-08-27 03:57:56,039 >> Configuration saved in /model/output/mistral-7b-fastchat_evol_instruct_70k_beautified-e3lr4e-06/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-27 03:58:10,961 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/mistral-7b-fastchat_evol_instruct_70k_beautified-e3lr4e-06/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-27 03:58:10,962 >> tokenizer config file saved in /model/output/mistral-7b-fastchat_evol_instruct_70k_beautified-e3lr4e-06/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-27 03:58:10,962 >> Special tokens file saved in /model/output/mistral-7b-fastchat_evol_instruct_70k_beautified-e3lr4e-06/special_tokens_map.json
[INFO|trainer.py:3788] 2024-08-27 03:58:11,673 >>
***** Running Evaluation *****
[INFO|trainer.py:3790] 2024-08-27 03:58:11,674 >>   Num examples = 5200
[INFO|trainer.py:3793] 2024-08-27 03:58:11,674 >>   Batch size = 4
  0%|                                                                                                      | 0/163 [00:00<?, ?it/s]
***** train metrics *****
  epoch                    =     2.9508
  total_flos               =   175195GF
  train_loss               =     0.6192
  train_runtime            = 1:50:45.11
  train_samples_per_second =     21.128
  train_steps_per_second   =       0.02
Figure saved at: /model/output/mistral-7b-fastchat_evol_instruct_70k_beautified-e3lr4e-06/training_loss.png































100%|████████████████████████████████████████████████████████████████████████████████████████████| 163/163 [01:03<00:00,  2.59it/s]
[INFO|modelcard.py:449] 2024-08-27 03:59:15,152 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
***** eval metrics *****
  epoch                   =     2.9508
  eval_loss               =     0.7518
  eval_runtime            = 0:01:03.47
  eval_samples_per_second =     81.918
  eval_steps_per_second   =      2.568