  0%|                                                                                            | 0/60 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  2%|█▍                                                                                  | 1/60 [00:29<28:33, 29.05s/it]

  3%|██▊                                                                                 | 2/60 [00:53<25:25, 26.30s/it]

  5%|████▏                                                                               | 3/60 [01:17<24:11, 25.47s/it]

  7%|█████▌                                                                              | 4/60 [01:41<23:15, 24.91s/it]
  7%|█████▌                                                                              | 4/60 [01:41<23:15, 24.91s/it][INFO|trainer.py:3478] 2024-08-13 19:11:08,740 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4
[INFO|configuration_utils.py:472] 2024-08-13 19:11:08,743 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:11:08,744 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/generation_config.json
[2024-08-13 19:11:23,346] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step4 is about to be saved!
[2024-08-13 19:11:23,355] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/global_step4/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:11:23,355] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/global_step4/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:11:23,368] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/global_step4/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:11:23,370] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/global_step4/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|modeling_utils.py:2698] 2024-08-13 19:11:22,795 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:11:22,797 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:11:22,797 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/special_tokens_map.json
[2024-08-13 19:11:34,766] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/global_step4/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:11:34,766] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4/global_step4/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:11:37,410] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.0506, 'grad_norm': 5.448081758622278, 'learning_rate': 9.166666666666666e-06, 'epoch': 1.23}
  8%|███████                                                                             | 5/60 [02:42<34:29, 37.63s/it]

 10%|████████▍                                                                           | 6/60 [03:06<29:47, 33.10s/it]

 12%|█████████▊                                                                          | 7/60 [03:30<26:41, 30.21s/it]

 13%|███████████▏                                                                        | 8/60 [03:54<24:30, 28.27s/it][INFO|trainer.py:3478] 2024-08-13 19:13:24,451 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8
[INFO|configuration_utils.py:472] 2024-08-13 19:13:24,454 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:13:24,455 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:13:40,491 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:13:40,492 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:13:40,492 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/special_tokens_map.json
[2024-08-13 19:13:41,361] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step8 is about to be saved!
[2024-08-13 19:13:41,371] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/global_step8/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:13:41,372] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/global_step8/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:13:41,386] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/global_step8/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:13:41,388] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/global_step8/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:13:53,340] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/global_step8/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:13:53,340] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8/global_step8/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-13 19:14:00,012 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-4] due to args.save_total_limit
[2024-08-13 19:14:00,009] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step8 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 15%|████████████▌                                                                       | 9/60 [05:13<37:32, 44.16s/it]

 17%|█████████████▊                                                                     | 10/60 [05:38<31:41, 38.02s/it]

 18%|███████████████▏                                                                   | 11/60 [06:02<27:35, 33.79s/it]

 20%|████████████████▌                                                                  | 12/60 [06:26<24:37, 30.79s/it]
 20%|████████████████▌                                                                  | 12/60 [06:26<24:37, 30.79s/it][INFO|trainer.py:3478] 2024-08-13 19:15:55,904 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12
[INFO|configuration_utils.py:472] 2024-08-13 19:15:55,907 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:15:55,908 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:16:10,167 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:16:10,168 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:16:10,168 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/special_tokens_map.json
[2024-08-13 19:16:10,867] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step12 is about to be saved!
[2024-08-13 19:16:10,876] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/global_step12/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:16:10,877] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/global_step12/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:16:10,889] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/global_step12/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:16:10,892] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/global_step12/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:16:26,543] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/global_step12/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:16:26,543] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12/global_step12/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-13 19:16:28,723 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-8] due to args.save_total_limit
[2024-08-13 19:16:28,720] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step12 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.6293, 'grad_norm': 1.8102983059253404, 'learning_rate': 7.833333333333333e-06, 'epoch': 3.2}

 23%|███████████████████▎                                                               | 14/60 [08:09<29:55, 39.03s/it]

 25%|████████████████████▊                                                              | 15/60 [08:33<25:53, 34.53s/it]

 27%|██████████████████████▏                                                            | 16/60 [08:57<22:58, 31.34s/it]
 27%|██████████████████████▏                                                            | 16/60 [08:57<22:58, 31.34s/it][INFO|trainer.py:3478] 2024-08-13 19:18:28,757 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16
[INFO|configuration_utils.py:472] 2024-08-13 19:18:28,761 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:18:28,761 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:18:43,479 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:18:43,480 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:18:43,480 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/special_tokens_map.json
[2024-08-13 19:18:44,471] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step16 is about to be saved!
[2024-08-13 19:18:44,480] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/global_step16/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:18:44,480] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/global_step16/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:18:44,494] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/global_step16/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:18:44,495] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/global_step16/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-13 19:19:03,205 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-12] due to args.save_total_limit
[2024-08-13 19:19:03,194] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/global_step16/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:19:03,195] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16/global_step16/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:19:03,201] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step16 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 28%|███████████████████████▌                                                           | 17/60 [10:14<32:17, 45.05s/it]

 30%|████████████████████████▉                                                          | 18/60 [10:38<27:08, 38.76s/it]
{'loss': 0.4784, 'grad_norm': 1.4753568864095226, 'learning_rate': 7e-06, 'epoch': 4.43}

 32%|██████████████████████████▎                                                        | 19/60 [11:03<23:31, 34.43s/it]

 33%|███████████████████████████▋                                                       | 20/60 [11:27<20:52, 31.32s/it][INFO|trainer.py:3478] 2024-08-13 19:20:59,185 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20
[INFO|configuration_utils.py:472] 2024-08-13 19:20:59,189 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:20:59,189 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:21:13,207 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:21:13,209 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:21:13,209 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/special_tokens_map.json
[2024-08-13 19:21:13,939] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step20 is about to be saved!
[2024-08-13 19:21:13,949] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:21:13,949] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:21:13,962] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:21:13,964] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/global_step20/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:21:29,000] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/global_step20/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:21:29,000] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20/global_step20/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:21:32,204] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step20 is ready now!
[INFO|trainer.py:3570] 2024-08-13 19:21:32,208 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-16] due to args.save_total_limit
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.3371, 'grad_norm': 1.753898025867237, 'learning_rate': 6.5000000000000004e-06, 'epoch': 5.17}

 37%|██████████████████████████████▍                                                    | 22/60 [13:10<24:47, 39.14s/it]

 38%|███████████████████████████████▊                                                   | 23/60 [13:34<21:21, 34.63s/it]

 40%|█████████████████████████████████▏                                                 | 24/60 [13:58<18:53, 31.47s/it]

 40%|█████████████████████████████████▏                                                 | 24/60 [13:58<18:53, 31.47s/it][INFO|trainer.py:3478] 2024-08-13 19:23:31,688 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24
[INFO|configuration_utils.py:472] 2024-08-13 19:23:31,691 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:23:31,691 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:23:46,091 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:23:46,092 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:23:46,092 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/special_tokens_map.json
[2024-08-13 19:23:47,071] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step24 is about to be saved!
[2024-08-13 19:23:47,080] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/global_step24/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:23:47,080] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/global_step24/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:23:47,094] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/global_step24/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:23:47,095] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/global_step24/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-13 19:24:05,780 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-20] due to args.save_total_limit
[2024-08-13 19:24:05,537] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/global_step24/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:24:05,538] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24/global_step24/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:24:05,776] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step24 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 42%|██████████████████████████████████▌                                                | 25/60 [15:15<26:16, 45.05s/it]

 43%|███████████████████████████████████▉                                               | 26/60 [15:39<21:58, 38.77s/it]

 45%|█████████████████████████████████████▎                                             | 27/60 [16:03<18:56, 34.44s/it]

 47%|██████████████████████████████████████▋                                            | 28/60 [16:27<16:41, 31.31s/it]
 47%|██████████████████████████████████████▋                                            | 28/60 [16:27<16:41, 31.31s/it][INFO|trainer.py:3478] 2024-08-13 19:26:01,752 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28
[INFO|configuration_utils.py:472] 2024-08-13 19:26:01,755 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:26:01,755 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:26:15,646 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:26:15,648 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:26:15,648 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/special_tokens_map.json
[2024-08-13 19:26:16,390] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step28 is about to be saved!
[2024-08-13 19:26:16,399] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/global_step28/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:26:16,399] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/global_step28/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:26:16,412] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/global_step28/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:26:16,414] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/global_step28/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:26:33,357] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/global_step28/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:26:33,357] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28/global_step28/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:26:34,659] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step28 is ready now!
[INFO|trainer.py:3570] 2024-08-13 19:26:34,663 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-24] due to args.save_total_limit
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 48%|████████████████████████████████████████                                           | 29/60 [17:45<23:24, 45.31s/it]
{'loss': 0.1924, 'grad_norm': 1.5927143846109557, 'learning_rate': 5.1666666666666675e-06, 'epoch': 7.14}

 50%|█████████████████████████████████████████▌                                         | 30/60 [18:09<19:30, 39.02s/it]

 52%|██████████████████████████████████████████▉                                        | 31/60 [18:33<16:42, 34.58s/it]

 53%|████████████████████████████████████████████▎                                      | 32/60 [18:58<14:40, 31.43s/it][INFO|trainer.py:3478] 2024-08-13 19:28:34,364 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32
[INFO|configuration_utils.py:472] 2024-08-13 19:28:34,368 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:28:34,368 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:28:48,849 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:28:48,850 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:28:48,850 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/special_tokens_map.json
[2024-08-13 19:28:49,831] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step32 is about to be saved!
[2024-08-13 19:28:49,840] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/global_step32/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:28:49,840] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/global_step32/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:28:49,854] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/global_step32/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:28:49,855] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/global_step32/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:29:07,260] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/global_step32/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:29:07,261] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32/global_step32/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:29:08,361] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step32 is ready now!
[INFO|trainer.py:3570] 2024-08-13 19:29:08,365 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-28] due to args.save_total_limit
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 55%|█████████████████████████████████████████████▋                                     | 33/60 [20:14<20:15, 45.03s/it]

 57%|███████████████████████████████████████████████                                    | 34/60 [20:39<16:49, 38.84s/it]

 58%|████████████████████████████████████████████████▍                                  | 35/60 [21:03<14:21, 34.47s/it]

 60%|█████████████████████████████████████████████████▊                                 | 36/60 [21:27<12:32, 31.34s/it]

 60%|█████████████████████████████████████████████████▊                                 | 36/60 [21:27<12:32, 31.34s/it][INFO|trainer.py:3478] 2024-08-13 19:31:04,378 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36
[INFO|configuration_utils.py:472] 2024-08-13 19:31:04,381 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:31:04,382 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:31:18,257 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:31:18,259 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:31:18,259 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/special_tokens_map.json
[2024-08-13 19:31:19,020] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step36 is about to be saved!
[2024-08-13 19:31:19,029] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/global_step36/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:31:19,029] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/global_step36/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:31:19,042] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/global_step36/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:31:19,044] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/global_step36/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-13 19:31:37,391 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-32] due to args.save_total_limit
[2024-08-13 19:31:37,380] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/global_step36/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:31:37,381] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36/global_step36/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:31:37,388] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step36 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 62%|███████████████████████████████████████████████████▏                               | 37/60 [22:45<17:20, 45.22s/it]

 63%|████████████████████████████████████████████████████▌                              | 38/60 [23:09<14:16, 38.92s/it]

 65%|█████████████████████████████████████████████████████▉                             | 39/60 [23:33<12:04, 34.48s/it]
{'loss': 0.1064, 'grad_norm': 1.3558217229426133, 'learning_rate': 3.5e-06, 'epoch': 9.6}


 67%|███████████████████████████████████████████████████████▎                           | 40/60 [23:58<10:31, 31.56s/it][INFO|trainer.py:3478] 2024-08-13 19:33:36,576 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40
[INFO|configuration_utils.py:472] 2024-08-13 19:33:36,579 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:33:36,579 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:33:51,058 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:33:51,059 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:33:51,059 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/special_tokens_map.json
[2024-08-13 19:33:52,020] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step40 is about to be saved!
[2024-08-13 19:33:52,029] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/global_step40/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:33:52,029] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/global_step40/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:33:52,042] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/global_step40/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:33:52,043] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/global_step40/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:34:09,286] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/global_step40/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:34:09,287] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40/global_step40/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-13 19:34:10,614 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-36] due to args.save_total_limit
[2024-08-13 19:34:10,610] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step40 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.0671, 'grad_norm': 1.8225311380245919, 'learning_rate': 3.1666666666666667e-06, 'epoch': 10.09}
 68%|████████████████████████████████████████████████████████▋                          | 41/60 [25:14<14:17, 45.12s/it]

 70%|██████████████████████████████████████████████████████████                         | 42/60 [25:39<11:38, 38.83s/it]


 73%|████████████████████████████████████████████████████████████▊                      | 44/60 [26:27<08:23, 31.50s/it]
 73%|████████████████████████████████████████████████████████████▊                      | 44/60 [26:27<08:23, 31.50s/it][INFO|trainer.py:3478] 2024-08-13 19:36:07,058 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44
[INFO|configuration_utils.py:472] 2024-08-13 19:36:07,061 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:36:07,062 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/generation_config.json
[2024-08-13 19:36:21,939] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step44 is about to be saved!
[2024-08-13 19:36:21,948] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/global_step44/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:36:21,949] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/global_step44/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:36:21,961] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/global_step44/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:36:21,963] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/global_step44/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|modeling_utils.py:2698] 2024-08-13 19:36:21,139 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:36:21,140 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:36:21,141 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/special_tokens_map.json
[INFO|trainer.py:3570] 2024-08-13 19:36:40,359 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-40] due to args.save_total_limit
[2024-08-13 19:36:40,122] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/global_step44/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:36:40,123] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44/global_step44/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:36:40,354] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step44 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.0762, 'grad_norm': 0.8865125979449785, 'learning_rate': 2.5e-06, 'epoch': 11.08}
 75%|██████████████████████████████████████████████████████████████▎                    | 45/60 [27:45<11:19, 45.33s/it]
 77%|███████████████████████████████████████████████████████████████▋                   | 46/60 [28:09<09:04, 38.87s/it]
 77%|███████████████████████████████████████████████████████████████▋                   | 46/60 [28:09<09:04, 38.87s/it]
 78%|█████████████████████████████████████████████████████████████████                  | 47/60 [28:33<07:27, 34.45s/it]
 78%|█████████████████████████████████████████████████████████████████                  | 47/60 [28:33<07:27, 34.45s/it]
 80%|██████████████████████████████████████████████████████████████████▍                | 48/60 [28:57<06:16, 31.35s/it]
[INFO|configuration_utils.py:769] 2024-08-13 19:38:38,279 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/generation_config.jsonto /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:38:53,284 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/special_tokens_map.jsons been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:38:53,284 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/special_tokens_map.jsons been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/model.safetensors.index.json.
[2024-08-13 19:38:54,225] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step48 is about to be saved!
[2024-08-13 19:38:54,234] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/global_step48/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:38:54,234] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/global_step48/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:38:54,248] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/global_step48/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:38:54,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/global_step48/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:39:10,956] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/global_step48/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:39:10,957] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48/global_step48/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-13 19:39:12,698 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-44] due to args.save_total_limit
[2024-08-13 19:39:12,693] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step48 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 82%|███████████████████████████████████████████████████████████████████▊               | 49/60 [30:14<08:15, 45.06s/it]

 83%|█████████████████████████████████████████████████████████████████████▏             | 50/60 [30:38<06:27, 38.79s/it]

 85%|██████████████████████████████████████████████████████████████████████▌            | 51/60 [31:02<05:09, 34.36s/it]

 87%|███████████████████████████████████████████████████████████████████████▉           | 52/60 [31:26<04:09, 31.24s/it]
 87%|███████████████████████████████████████████████████████████████████████▉           | 52/60 [31:26<04:09, 31.24s/it][INFO|trainer.py:3478] 2024-08-13 19:41:08,529 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52
[INFO|configuration_utils.py:472] 2024-08-13 19:41:08,532 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:41:08,532 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:41:22,776 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:41:22,778 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:41:22,779 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/special_tokens_map.json
[2024-08-13 19:41:23,590] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step52 is about to be saved!
[2024-08-13 19:41:23,599] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/global_step52/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:41:23,599] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/global_step52/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:41:23,612] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/global_step52/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:41:23,614] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/global_step52/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:41:41,966] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/global_step52/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:41:41,967] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52/global_step52/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:41:41,972] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step52 is ready now!
[INFO|trainer.py:3570] 2024-08-13 19:41:41,976 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-48] due to args.save_total_limit
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 88%|█████████████████████████████████████████████████████████████████████████▎         | 53/60 [32:44<05:16, 45.24s/it]

 90%|██████████████████████████████████████████████████████████████████████████▋        | 54/60 [33:08<03:53, 38.87s/it]

 92%|████████████████████████████████████████████████████████████████████████████       | 55/60 [33:32<02:52, 34.42s/it]

 93%|█████████████████████████████████████████████████████████████████████████████▍     | 56/60 [33:56<02:05, 31.32s/it]

 93%|█████████████████████████████████████████████████████████████████████████████▍     | 56/60 [33:56<02:05, 31.32s/it][INFO|trainer.py:3478] 2024-08-13 19:43:39,930 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56
[INFO|configuration_utils.py:472] 2024-08-13 19:43:39,933 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:43:39,933 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:43:54,643 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:43:54,644 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:43:54,644 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/special_tokens_map.json
[2024-08-13 19:43:55,595] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step56 is about to be saved!
[2024-08-13 19:43:55,604] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/global_step56/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:43:55,604] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/global_step56/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:43:55,617] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/global_step56/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:43:55,619] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/global_step56/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:44:14,074] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/global_step56/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:44:14,074] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56/global_step56/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:44:14,163] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step56 is ready now!
[INFO|trainer.py:3570] 2024-08-13 19:44:14,168 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-52] due to args.save_total_limit
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 95%|██████████████████████████████████████████████████████████████████████████████▊    | 57/60 [35:13<02:14, 44.92s/it]

 97%|████████████████████████████████████████████████████████████████████████████████▏  | 58/60 [35:37<01:17, 38.68s/it]
{'loss': 0.0387, 'grad_norm': 0.42886930073770685, 'learning_rate': 3.3333333333333335e-07, 'epoch': 14.28}


100%|███████████████████████████████████████████████████████████████████████████████████| 60/60 [36:25<00:00, 31.19s/it]
100%|███████████████████████████████████████████████████████████████████████████████████| 60/60 [36:25<00:00, 31.19s/it][INFO|trainer.py:3478] 2024-08-13 19:45:51,336 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60
[INFO|configuration_utils.py:472] 2024-08-13 19:45:51,339 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:45:51,340 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:46:05,007 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:46:05,008 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:46:05,008 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/special_tokens_map.json
[2024-08-13 19:46:05,803] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step60 is about to be saved!
[2024-08-13 19:46:05,812] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:46:05,812] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:46:05,825] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:46:05,828] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-13 19:46:23,657 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-56] due to args.save_total_limit
[2024-08-13 19:46:23,201] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:46:23,202] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-13 19:46:23,652] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step60 is ready now!
[INFO|trainer.py:3478] 2024-08-13 19:46:43,580 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60
[INFO|configuration_utils.py:472] 2024-08-13 19:46:43,583 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:46:43,583 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:47:24,639 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:47:24,640 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:47:24,641 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/special_tokens_map.json
[2024-08-13 19:47:25,629] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step60 is about to be saved!
[2024-08-13 19:47:25,639] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-13 19:47:25,639] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-13 19:47:25,657] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-13 19:47:25,659] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-13 19:48:42,433] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-13 19:48:42,443] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/checkpoint-60/global_step60/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:2383] 2024-08-13 19:48:45,373 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|███████████████████████████████████████████████████████████████████████████████████| 60/60 [39:26<00:00, 39.45s/it]
[2024-08-13 19:48:45,366] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step60 is ready now!
{'train_runtime': 2376.5613, 'train_samples_per_second': 5.68, 'train_steps_per_second': 0.025, 'train_loss': 0.3654209117715557, 'epoch': 14.77}
[INFO|trainer.py:3478] 2024-08-13 19:48:52,674 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5
[INFO|configuration_utils.py:472] 2024-08-13 19:48:52,678 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/config.json
[INFO|configuration_utils.py:769] 2024-08-13 19:48:52,678 >> Configuration saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-13 19:49:08,612 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-13 19:49:08,614 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-13 19:49:08,614 >> Special tokens file saved in /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/special_tokens_map.json
[INFO|trainer.py:3788] 2024-08-13 19:49:09,350 >>
***** Running Evaluation *****
[INFO|trainer.py:3790] 2024-08-13 19:49:09,350 >>   Num examples = 100
[INFO|trainer.py:3793] 2024-08-13 19:49:09,350 >>   Batch size = 1
 13%|███████████▏                                                                        | 2/15 [00:00<00:03,  3.27it/s]
***** train metrics *****
  epoch                    =    14.7692
  total_flos               =     3064GF
  train_loss               =     0.3654
  train_runtime            = 0:39:36.56
  train_samples_per_second =       5.68
  train_steps_per_second   =      0.025
Figure saved at: /model/output/Llama-2-7b-hf-cluster_pair_score_WHATMAKESGOOD_1k-e15lr1e-5/training_loss.png
 53%|████████████████████████████████████████████▊                                       | 8/15 [00:02<00:02,  3.07it/s]
 93%|█████████████████████████████████████████████████████████████████████████████▍     | 14/15 [00:04<00:00,  3.07it/s]
 93%|█████████████████████████████████████████████████████████████████████████████▍     | 14/15 [00:04<00:00,  3.07it/s]
***** eval metrics *****
  epoch                   =    14.7692
  eval_loss               =      1.955
  eval_runtime            = 0:00:05.28
  eval_samples_per_second =     18.937
100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:04<00:00,  3.09it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:04<00:00,  3.09it/s]