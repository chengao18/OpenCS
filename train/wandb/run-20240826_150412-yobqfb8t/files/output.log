  0%|                                                                           | 0/105 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  1%|▋                                                                  | 1/105 [00:30<52:56, 30.54s/it]

  2%|█▎                                                                 | 2/105 [00:56<47:26, 27.63s/it]
{'loss': 1.2737, 'grad_norm': 3.929839781584402, 'learning_rate': 1.961904761904762e-05, 'epoch': 0.28}


  4%|██▌                                                                | 4/105 [01:46<43:55, 26.09s/it]
{'loss': 1.1465, 'grad_norm': 2.2120222793616002, 'learning_rate': 1.923809523809524e-05, 'epoch': 0.57}


  6%|███▊                                                               | 6/105 [02:36<41:44, 25.30s/it]

  7%|████▍                                                              | 7/105 [03:00<40:42, 24.93s/it]

  8%|█████                                                              | 8/105 [03:24<39:56, 24.71s/it]

  9%|█████▋                                                             | 9/105 [03:49<39:20, 24.59s/it]

 10%|██████▎                                                           | 10/105 [04:13<38:49, 24.52s/it]

 10%|██████▉                                                           | 11/105 [04:37<38:15, 24.42s/it]

 11%|███████▌                                                          | 12/105 [05:01<37:41, 24.31s/it]
{'loss': 0.7536, 'grad_norm': 1.81814092026576, 'learning_rate': 1.7714285714285717e-05, 'epoch': 1.7}


 13%|████████▊                                                         | 14/105 [05:50<36:51, 24.30s/it]

 14%|█████████▍                                                        | 15/105 [06:14<36:28, 24.31s/it]

 15%|██████████                                                        | 16/105 [06:38<36:00, 24.27s/it]

 16%|██████████▋                                                       | 17/105 [07:03<35:33, 24.25s/it]

 17%|███████████▎                                                      | 18/105 [07:27<35:12, 24.29s/it]

 18%|███████████▉                                                      | 19/105 [07:51<34:40, 24.19s/it]

 19%|████████████▌                                                     | 20/105 [08:15<34:16, 24.20s/it]

 20%|█████████████▏                                                    | 21/105 [08:39<33:51, 24.18s/it]

 21%|█████████████▊                                                    | 22/105 [09:03<33:21, 24.12s/it]

 22%|██████████████▍                                                   | 23/105 [09:27<32:59, 24.13s/it]

 23%|███████████████                                                   | 24/105 [09:51<32:32, 24.11s/it]
{'loss': 0.2357, 'grad_norm': 1.3142566732491532, 'learning_rate': 1.542857142857143e-05, 'epoch': 3.4}


 25%|████████████████▎                                                 | 26/105 [10:40<31:58, 24.28s/it]

 26%|████████████████▉                                                 | 27/105 [11:05<31:32, 24.26s/it]

 27%|█████████████████▌                                                | 28/105 [11:29<31:08, 24.26s/it]
{'loss': 0.1697, 'grad_norm': 1.5516927428193656, 'learning_rate': 1.4666666666666666e-05, 'epoch': 3.96}


 29%|██████████████████▊                                               | 30/105 [12:17<30:16, 24.22s/it]

 30%|███████████████████▍                                              | 31/105 [12:41<29:50, 24.19s/it]

 30%|████████████████████                                              | 32/105 [13:05<29:25, 24.18s/it]
{'loss': 0.0791, 'grad_norm': 0.9250136464633054, 'learning_rate': 1.3904761904761905e-05, 'epoch': 4.53}

 31%|████████████████████▋                                             | 33/105 [13:30<29:04, 24.23s/it]

 32%|█████████████████████▎                                            | 34/105 [13:54<28:38, 24.21s/it]


 34%|██████████████████████▋                                           | 36/105 [14:42<27:50, 24.21s/it]

 35%|███████████████████████▎                                          | 37/105 [15:07<27:28, 24.25s/it]

 36%|███████████████████████▉                                          | 38/105 [15:31<27:01, 24.20s/it]

 37%|████████████████████████▌                                         | 39/105 [15:55<26:28, 24.07s/it]

 38%|█████████████████████████▏                                        | 40/105 [16:19<26:03, 24.05s/it]

 39%|█████████████████████████▊                                        | 41/105 [16:43<25:37, 24.02s/it]

 40%|██████████████████████████▍                                       | 42/105 [17:07<25:15, 24.06s/it]

 41%|███████████████████████████                                       | 43/105 [17:31<24:56, 24.13s/it]

 42%|███████████████████████████▋                                      | 44/105 [17:55<24:32, 24.15s/it]

 43%|████████████████████████████▎                                     | 45/105 [18:19<24:06, 24.11s/it]

 44%|████████████████████████████▉                                     | 46/105 [18:43<23:42, 24.10s/it]

 45%|█████████████████████████████▌                                    | 47/105 [19:07<23:15, 24.07s/it]

 46%|██████████████████████████████▏                                   | 48/105 [19:32<22:56, 24.14s/it]

 47%|██████████████████████████████▊                                   | 49/105 [19:56<22:29, 24.10s/it]

 48%|███████████████████████████████▍                                  | 50/105 [20:20<22:05, 24.10s/it]

 49%|████████████████████████████████                                  | 51/105 [20:44<21:38, 24.04s/it]

 50%|████████████████████████████████▋                                 | 52/105 [21:08<21:14, 24.04s/it]

 50%|█████████████████████████████████▎                                | 53/105 [21:32<20:56, 24.16s/it]

 51%|█████████████████████████████████▉                                | 54/105 [21:56<20:23, 23.98s/it]

 52%|██████████████████████████████████▌                               | 55/105 [22:20<20:03, 24.07s/it]

 53%|███████████████████████████████████▏                              | 56/105 [22:44<19:39, 24.08s/it]

 54%|███████████████████████████████████▊                              | 57/105 [23:08<19:14, 24.06s/it]

 55%|████████████████████████████████████▍                             | 58/105 [23:32<18:52, 24.09s/it]

 56%|█████████████████████████████████████                             | 59/105 [23:56<18:21, 23.95s/it]

 57%|█████████████████████████████████████▋                            | 60/105 [24:20<18:02, 24.05s/it]

 58%|██████████████████████████████████████▎                           | 61/105 [24:44<17:37, 24.03s/it]

 59%|██████████████████████████████████████▉                           | 62/105 [25:08<17:16, 24.11s/it]

 60%|███████████████████████████████████████▌                          | 63/105 [25:32<16:50, 24.06s/it]

 61%|████████████████████████████████████████▏                         | 64/105 [25:56<16:27, 24.08s/it]
{'loss': 0.0078, 'grad_norm': 1.45789522220481, 'learning_rate': 7.809523809523811e-06, 'epoch': 9.06}


 63%|█████████████████████████████████████████▍                        | 66/105 [26:44<15:37, 24.03s/it]

 64%|██████████████████████████████████████████                        | 67/105 [27:09<15:14, 24.06s/it]
{'loss': 0.0052, 'grad_norm': 0.2941941763471011, 'learning_rate': 7.238095238095239e-06, 'epoch': 9.49}

 65%|██████████████████████████████████████████▋                       | 68/105 [27:33<14:50, 24.07s/it]

 66%|███████████████████████████████████████████▎                      | 69/105 [27:57<14:26, 24.08s/it]

 67%|████████████████████████████████████████████                      | 70/105 [28:21<14:01, 24.05s/it]

 68%|████████████████████████████████████████████▋                     | 71/105 [28:45<13:37, 24.05s/it]


 70%|█████████████████████████████████████████████▉                    | 73/105 [29:32<12:45, 23.92s/it]

 70%|██████████████████████████████████████████████▌                   | 74/105 [29:57<12:24, 24.01s/it]

 71%|███████████████████████████████████████████████▏                  | 75/105 [30:21<12:01, 24.05s/it]
{'loss': 0.0027, 'grad_norm': 0.13651703531646428, 'learning_rate': 5.7142857142857145e-06, 'epoch': 10.62}

 72%|███████████████████████████████████████████████▊                  | 76/105 [30:45<11:40, 24.16s/it]


 74%|█████████████████████████████████████████████████                 | 78/105 [31:33<10:51, 24.12s/it]
{'loss': 0.0043, 'grad_norm': 0.22916887112481985, 'learning_rate': 5.142857142857142e-06, 'epoch': 11.04}


 76%|██████████████████████████████████████████████████▎               | 80/105 [32:22<10:02, 24.11s/it]
{'loss': 0.0023, 'grad_norm': 0.10501553149532043, 'learning_rate': 4.761904761904762e-06, 'epoch': 11.33}

 77%|██████████████████████████████████████████████████▉               | 81/105 [32:45<09:35, 23.99s/it]


 79%|████████████████████████████████████████████████████▏             | 83/105 [33:33<08:49, 24.06s/it]
{'loss': 0.0016, 'grad_norm': 0.11406887359970902, 'learning_rate': 4.190476190476191e-06, 'epoch': 11.75}

 80%|████████████████████████████████████████████████████▊             | 84/105 [33:57<08:23, 23.98s/it]

 81%|█████████████████████████████████████████████████████▍            | 85/105 [34:21<08:00, 24.02s/it]


 83%|██████████████████████████████████████████████████████▋           | 87/105 [35:09<07:10, 23.93s/it]

 84%|███████████████████████████████████████████████████████▎          | 88/105 [35:33<06:47, 23.96s/it]

 85%|███████████████████████████████████████████████████████▉          | 89/105 [35:57<06:21, 23.85s/it]

 86%|████████████████████████████████████████████████████████▌         | 90/105 [36:21<05:59, 23.94s/it]

 87%|█████████████████████████████████████████████████████████▏        | 91/105 [36:44<05:33, 23.83s/it]

 88%|█████████████████████████████████████████████████████████▊        | 92/105 [37:08<05:09, 23.79s/it]

 89%|██████████████████████████████████████████████████████████▍       | 93/105 [37:32<04:45, 23.80s/it]

 90%|███████████████████████████████████████████████████████████       | 94/105 [37:56<04:22, 23.84s/it]

 90%|███████████████████████████████████████████████████████████▋      | 95/105 [38:20<03:58, 23.90s/it]
{'loss': 0.0019, 'grad_norm': 0.3293570254269342, 'learning_rate': 1.904761904761905e-06, 'epoch': 13.45}

 91%|████████████████████████████████████████████████████████████▎     | 96/105 [38:44<03:34, 23.83s/it]


 93%|█████████████████████████████████████████████████████████████▌    | 98/105 [39:31<02:46, 23.81s/it]

 94%|██████████████████████████████████████████████████████████████▏   | 99/105 [39:55<02:23, 23.85s/it]

 95%|█████████████████████████████████████████████████████████████▉   | 100/105 [40:19<01:59, 23.87s/it]

 96%|██████████████████████████████████████████████████████████████▌  | 101/105 [40:43<01:35, 23.90s/it]

 97%|███████████████████████████████████████████████████████████████▏ | 102/105 [41:07<01:11, 23.91s/it]

 98%|███████████████████████████████████████████████████████████████▊ | 103/105 [41:31<00:47, 23.81s/it]

 99%|████████████████████████████████████████████████████████████████▍| 104/105 [41:54<00:23, 23.84s/it]
100%|█████████████████████████████████████████████████████████████████| 105/105 [42:18<00:00, 23.82s/it][INFO|trainer.py:2383] 2024-08-26 15:46:37,777 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|█████████████████████████████████████████████████████████████████| 105/105 [42:18<00:00, 24.18s/it]
{'loss': 0.0006, 'grad_norm': 0.026743261050845395, 'learning_rate': 0.0, 'epoch': 14.87}
{'train_runtime': 2546.7219, 'train_samples_per_second': 5.301, 'train_steps_per_second': 0.041, 'train_loss': 0.18254371135928002, 'epoch': 14.87}
[INFO|trainer.py:3478] 2024-08-26 15:46:44,925 >> Saving model checkpoint to /model/output/llama2-7b-cluster_pair_score_myprompt_sharegpt_refined-e15lr2e-05
[INFO|configuration_utils.py:472] 2024-08-26 15:46:44,928 >> Configuration saved in /model/output/llama2-7b-cluster_pair_score_myprompt_sharegpt_refined-e15lr2e-05/config.json
[INFO|configuration_utils.py:769] 2024-08-26 15:46:44,929 >> Configuration saved in /model/output/llama2-7b-cluster_pair_score_myprompt_sharegpt_refined-e15lr2e-05/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-26 15:46:59,175 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/llama2-7b-cluster_pair_score_myprompt_sharegpt_refined-e15lr2e-05/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-26 15:46:59,176 >> tokenizer config file saved in /model/output/llama2-7b-cluster_pair_score_myprompt_sharegpt_refined-e15lr2e-05/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-26 15:46:59,177 >> Special tokens file saved in /model/output/llama2-7b-cluster_pair_score_myprompt_sharegpt_refined-e15lr2e-05/special_tokens_map.json
[INFO|trainer.py:3788] 2024-08-26 15:46:59,968 >>
***** Running Evaluation *****
[INFO|trainer.py:3790] 2024-08-26 15:46:59,969 >>   Num examples = 100
[INFO|trainer.py:3793] 2024-08-26 15:46:59,969 >>   Batch size = 1
  8%|█████▍                                                              | 2/25 [00:00<00:07,  3.10it/s]
***** train metrics *****
  epoch                    =    14.8673
  total_flos               =     5795GF
  train_loss               =     0.1825
  train_runtime            = 0:42:26.72
  train_samples_per_second =      5.301
  train_steps_per_second   =      0.041
Figure saved at: /model/output/llama2-7b-cluster_pair_score_myprompt_sharegpt_refined-e15lr2e-05/training_loss.png




100%|███████████████████████████████████████████████████████████████████| 25/25 [00:08<00:00,  2.83it/s]
***** eval metrics *****
  epoch                   =    14.8673
  eval_loss               =     2.4192
  eval_runtime            = 0:00:09.14
  eval_samples_per_second =     10.936
100%|███████████████████████████████████████████████████████████████████| 25/25 [00:08<00:00,  2.86it/s]
[INFO|modelcard.py:449] 2024-08-26 15:47:09,113 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}