  0%|                                                                                | 0/75 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  1%|▎                           | 1/75 [00:35<43:18, 35.12s/it]

  3%|▋                           | 2/75 [01:03<37:58, 31.22s/it]

  4%|█                           | 3/75 [01:32<35:58, 29.98s/it]

  5%|█▍                          | 4/75 [02:00<34:32, 29.19s/it]

  7%|█▊                          | 5/75 [02:27<33:21, 28.60s/it]
  7%|█▊                          | 5/75 [02:27<33:21, 28.60s/it][INFO|trainer.py:3478] 2024-08-08 23:13:46,589 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5
[INFO|configuration_utils.py:472] 2024-08-08 23:13:46,593 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/config.json
[INFO|configuration_utils.py:769] 2024-08-08 23:13:46,593 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-08 23:14:00,706 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-08 23:14:00,707 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-08 23:14:00,708 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/special_tokens_map.json
[2024-08-08 23:14:01,262] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step5 is about to be saved!
[2024-08-08 23:14:01,271] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/global_step5/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-08 23:14:01,272] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/global_step5/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-08 23:14:01,285] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/global_step5/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-08 23:14:01,287] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/global_step5/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-08 23:14:19,281] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/global_step5/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-08 23:14:19,281] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5/global_step5/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
[2024-08-08 23:14:20,034] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5 is ready now!
  8%|██████████                                                                                                                    | 6/75 [03:37<49:02, 42.65s/it]

  9%|███████████▊                                                                                                                  | 7/75 [04:14<46:12, 40.78s/it]

 11%|█████████████▍                                                                                                                | 8/75 [05:10<51:04, 45.74s/it]

 12%|███████████████                                                                                                               | 9/75 [06:00<51:42, 47.01s/it]

 13%|████████████████▋                                                                                                            | 10/75 [06:53<52:47, 48.73s/it]

 15%|██████████████████▎                                                                                                          | 11/75 [07:45<53:15, 49.92s/it]
 15%|██████████████████▎                                                                                                          | 11/75 [07:45<53:15, 49.92s/it][INFO|trainer.py:3478] 2024-08-08 23:19:00,951 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11
[INFO|configuration_utils.py:472] 2024-08-08 23:19:00,954 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/config.json
[INFO|configuration_utils.py:769] 2024-08-08 23:19:00,955 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-08 23:19:15,745 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-08 23:19:15,748 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-08 23:19:15,748 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/special_tokens_map.json
[2024-08-08 23:19:16,421] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step11 is about to be saved!
[2024-08-08 23:19:16,445] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/global_step11/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-08 23:19:16,445] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/global_step11/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-08 23:19:16,458] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/global_step11/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-08 23:19:16,485] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/global_step11/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-08 23:19:35,548] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/global_step11/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-08 23:19:35,548] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11/global_step11/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-08 23:19:35,980] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step11 is ready now!
[INFO|trainer.py:3570] 2024-08-08 23:19:35,989 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-5] due to args.save_total_limit
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 16%|███████████████████▋                                                                                                       | 12/75 [09:33<1:11:00, 67.62s/it]
{'loss': 0.7681, 'grad_norm': 1.006072145938932, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.13}


 19%|██████████████████████▉                                                                                                    | 14/75 [11:19<1:00:42, 59.71s/it]

 20%|█████████████████████████                                                                                                    | 15/75 [12:13<57:59, 57.99s/it]

 21%|██████████████████████████▋                                                                                                  | 16/75 [13:01<53:58, 54.89s/it]
 21%|██████████████████████████▋                                                                                                  | 16/75 [13:01<53:58, 54.89s/it][INFO|trainer.py:3478] 2024-08-08 23:24:49,403 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16
[INFO|configuration_utils.py:472] 2024-08-08 23:24:49,407 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/config.json
[INFO|configuration_utils.py:769] 2024-08-08 23:24:49,408 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-08 23:25:04,380 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-08 23:25:04,381 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-08 23:25:04,381 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/special_tokens_map.json
[2024-08-08 23:25:05,072] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step16 is about to be saved!
[2024-08-08 23:25:05,096] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/global_step16/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-08 23:25:05,096] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/global_step16/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-08 23:25:05,109] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/global_step16/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-08 23:25:05,145] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/global_step16/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-08 23:25:23,902 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-11] due to args.save_total_limit
[2024-08-08 23:25:23,131] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/global_step16/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-08 23:25:23,132] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16/global_step16/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-08 23:25:23,893] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step16 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 23%|███████████████████████████▉                                                                                               | 17/75 [14:52<1:09:23, 71.78s/it]

 24%|█████████████████████████████▌                                                                                             | 18/75 [15:44<1:02:45, 66.07s/it]

 25%|███████████████████████████████▋                                                                                             | 19/75 [16:36<57:37, 61.73s/it]
{'loss': 0.5602, 'grad_norm': 1.0100005889173245, 'learning_rate': 7.4666666666666675e-06, 'epoch': 3.38}


 28%|███████████████████████████████████                                                                                          | 21/75 [18:19<50:39, 56.29s/it]

 29%|████████████████████████████████████▋                                                                                        | 22/75 [19:15<49:32, 56.09s/it]
 29%|████████████████████████████████████▋                                                                                        | 22/75 [19:15<49:32, 56.09s/it][INFO|trainer.py:3478] 2024-08-08 23:30:47,018 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22
[INFO|configuration_utils.py:472] 2024-08-08 23:30:47,022 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/config.json
[INFO|configuration_utils.py:769] 2024-08-08 23:30:47,022 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-08 23:31:02,209 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-08 23:31:02,210 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-08 23:31:02,211 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/special_tokens_map.json
[2024-08-08 23:31:03,060] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step22 is about to be saved!
[2024-08-08 23:31:03,084] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/global_step22/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-08 23:31:03,085] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/global_step22/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-08 23:31:03,098] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/global_step22/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-08 23:31:03,133] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/global_step22/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-08 23:31:22,017 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-16] due to args.save_total_limit
[2024-08-08 23:31:21,619] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/global_step22/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-08 23:31:21,619] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22/global_step22/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-08 23:31:22,012] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step22 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 31%|█████████████████████████████████████▋                                                                                     | 23/75 [20:59<1:01:05, 70.50s/it]
{'loss': 0.454, 'grad_norm': 1.1357480653330274, 'learning_rate': 6.9333333333333344e-06, 'epoch': 4.09}


 33%|█████████████████████████████████████████▋                                                                                   | 25/75 [22:45<51:15, 61.51s/it]

 35%|███████████████████████████████████████████▎                                                                                 | 26/75 [23:35<47:34, 58.27s/it]

 36%|█████████████████████████████████████████████                                                                                | 27/75 [24:30<45:43, 57.15s/it]

 37%|██████████████████████████████████████████████▋                                                                              | 28/75 [25:18<42:38, 54.43s/it]
 37%|██████████████████████████████████████████████▋                                                                              | 28/75 [25:18<42:38, 54.43s/it][INFO|trainer.py:3478] 2024-08-08 23:36:33,783 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28
[INFO|configuration_utils.py:472] 2024-08-08 23:36:33,786 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/config.json
[INFO|configuration_utils.py:769] 2024-08-08 23:36:33,787 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-08 23:36:48,085 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-08 23:36:48,086 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-08 23:36:48,086 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/special_tokens_map.json
[2024-08-08 23:36:48,846] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step28 is about to be saved!
[2024-08-08 23:36:48,870] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/global_step28/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-08 23:36:48,870] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/global_step28/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-08 23:36:48,883] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/global_step28/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-08 23:36:48,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/global_step28/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-08 23:37:07,067] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/global_step28/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-08 23:37:07,068] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28/global_step28/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-08 23:37:07,500] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step28 is ready now!
[INFO|trainer.py:3570] 2024-08-08 23:37:07,505 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-22] due to args.save_total_limit
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 39%|█████████████████████████████████████████▊                                                                  | 29/75 [27:05<53:53, 70.30s/it]
{'loss': 0.3587, 'grad_norm': 1.0738574720960816, 'learning_rate': 6.133333333333334e-06, 'epoch': 5.16}

 40%|███████████████████████████████████████████▏                                                                | 30/75 [27:55<47:59, 64.00s/it]


 43%|██████████████████████████████████████████████                                                              | 32/75 [29:40<41:42, 58.20s/it]
{'loss': 0.283, 'grad_norm': 1.0051551501711202, 'learning_rate': 5.733333333333334e-06, 'epoch': 5.69}

 44%|███████████████████████████████████████████████▌                                                            | 33/75 [30:31<39:13, 56.04s/it][INFO|trainer.py:3478] 2024-08-08 23:42:13,503 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33
[INFO|configuration_utils.py:472] 2024-08-08 23:42:13,506 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/config.json
[INFO|configuration_utils.py:769] 2024-08-08 23:42:13,507 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-08 23:42:28,757 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-08 23:42:28,759 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-08 23:42:28,759 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/special_tokens_map.json
[2024-08-08 23:42:29,580] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step33 is about to be saved!
[2024-08-08 23:42:29,604] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/global_step33/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-08 23:42:29,605] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/global_step33/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-08 23:42:29,618] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/global_step33/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-08 23:42:29,652] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/global_step33/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-08 23:42:48,509 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-28] due to args.save_total_limit
[2024-08-08 23:42:48,419] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/global_step33/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-08 23:42:48,420] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33/global_step33/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-08 23:42:48,504] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step33 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 45%|████████████████████████████████████████████████▉                                                           | 34/75 [32:23<49:44, 72.79s/it]

 47%|██████████████████████████████████████████████████▍                                                         | 35/75 [33:14<44:11, 66.29s/it]

 48%|███████████████████████████████████████████████████▊                                                        | 36/75 [34:14<41:55, 64.51s/it]

 49%|█████████████████████████████████████████████████████▎                                                      | 37/75 [35:40<44:51, 70.83s/it]
{'loss': 0.1711, 'grad_norm': 0.7801047513999246, 'learning_rate': 5.0666666666666676e-06, 'epoch': 6.58}


 52%|████████████████████████████████████████████████████████▏                                                   | 39/75 [39:08<53:13, 88.70s/it]
 52%|████████████████████████████████████████████████████████▏                                                   | 39/75 [39:08<53:13, 88.70s/it][INFO|trainer.py:3478] 2024-08-08 23:50:49,432 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39
[INFO|configuration_utils.py:472] 2024-08-08 23:50:49,436 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/config.json
[INFO|configuration_utils.py:769] 2024-08-08 23:50:49,437 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-08 23:51:05,103 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-08 23:51:05,104 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-08 23:51:05,105 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/special_tokens_map.json
[2024-08-08 23:51:05,865] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step39 is about to be saved!
[2024-08-08 23:51:05,907] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/global_step39/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-08 23:51:05,907] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/global_step39/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-08 23:51:05,920] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/global_step39/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-08 23:51:05,972] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/global_step39/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-08 23:51:28,523 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-33] due to args.save_total_limit
[2024-08-08 23:51:27,468] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/global_step39/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-08 23:51:27,469] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39/global_step39/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-08 23:51:28,517] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 53%|████████████████████████████████████████████████████████                                                 | 40/75 [41:44<1:03:34, 109.00s/it]

 55%|██████████████████████████████████████████████████████████▍                                                | 41/75 [43:23<59:57, 105.80s/it]

 56%|███████████████████████████████████████████████████████████▉                                               | 42/75 [44:51<55:21, 100.65s/it]

 57%|█████████████████████████████████████████████████████████████▎                                             | 43/75 [46:41<55:09, 103.42s/it]

 59%|██████████████████████████████████████████████████████████████▊                                            | 44/75 [48:22<53:04, 102.73s/it]

 60%|████████████████████████████████████████████████████████████████▊                                           | 45/75 [49:53<49:35, 99.18s/it]
 60%|████████████████████████████████████████████████████████████████▊                                           | 45/75 [49:53<49:35, 99.18s/it][INFO|trainer.py:3478] 2024-08-09 00:01:09,431 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45
[INFO|configuration_utils.py:472] 2024-08-09 00:01:09,435 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/config.json
[INFO|configuration_utils.py:769] 2024-08-09 00:01:09,435 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-09 00:01:30,748 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-09 00:01:30,750 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:01:30,751 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/special_tokens_map.json
[2024-08-09 00:01:31,879] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step45 is about to be saved!
[2024-08-09 00:01:31,890] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/global_step45/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:01:31,890] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/global_step45/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:01:31,904] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/global_step45/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-09 00:01:31,906] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/global_step45/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-09 00:01:51,016] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/global_step45/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:01:51,016] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45/global_step45/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-09 00:01:53,021 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-39] due to args.save_total_limit
[2024-08-09 00:01:53,007] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step45 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 61%|█████████████████████████████████████████████████████████████████▋                                         | 46/75 [52:40<57:42, 119.39s/it]

 63%|███████████████████████████████████████████████████████████████████                                        | 47/75 [54:06<51:01, 109.34s/it]

 64%|████████████████████████████████████████████████████████████████████▍                                      | 48/75 [55:46<47:57, 106.58s/it]

 65%|█████████████████████████████████████████████████████████████████████▉                                     | 49/75 [57:28<45:38, 105.35s/it]

 67%|███████████████████████████████████████████████████████████████████████▎                                   | 50/75 [59:01<42:18, 101.53s/it]
 67%|███████████████████████████████████████████████████████████████████████▎                                   | 50/75 [59:01<42:18, 101.53s/it][INFO|trainer.py:3478] 2024-08-09 00:11:14,643 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50
[INFO|configuration_utils.py:472] 2024-08-09 00:11:14,647 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/config.json
[INFO|configuration_utils.py:769] 2024-08-09 00:11:14,647 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-09 00:11:31,404 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-09 00:11:31,405 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:11:31,406 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/special_tokens_map.json
[2024-08-09 00:11:32,076] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step50 is about to be saved!
[2024-08-09 00:11:32,126] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:11:32,126] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:11:32,139] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-09 00:11:32,228] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[INFO|trainer.py:3570] 2024-08-09 00:11:52,339 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-45] due to args.save_total_limit
[2024-08-09 00:11:51,311] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:11:51,312] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50/global_step50/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-09 00:11:52,331] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 68%|███████████████████████████████████████████████████████████████████████▍                                 | 51/75 [1:01:51<48:51, 122.16s/it]

 69%|████████████████████████████████████████████████████████████████████████▊                                | 52/75 [1:03:05<41:19, 107.79s/it]

 71%|██████████████████████████████████████████████████████████████████████████▏                              | 53/75 [1:05:01<40:20, 110.01s/it]

 72%|███████████████████████████████████████████████████████████████████████████▌                             | 54/75 [1:06:43<37:44, 107.82s/it]

 73%|█████████████████████████████████████████████████████████████████████████████                            | 55/75 [1:08:12<34:00, 102.00s/it]

 75%|██████████████████████████████████████████████████████████████████████████████▍                          | 56/75 [1:10:01<32:57, 104.07s/it]
 75%|██████████████████████████████████████████████████████████████████████████████▍                          | 56/75 [1:10:01<32:57, 104.07s/it][INFO|trainer.py:3478] 2024-08-09 00:21:34,921 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56
[INFO|configuration_utils.py:472] 2024-08-09 00:21:34,925 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/config.json
[INFO|configuration_utils.py:769] 2024-08-09 00:21:34,925 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-09 00:21:50,779 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-09 00:21:50,780 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:21:50,780 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/special_tokens_map.json
[2024-08-09 00:21:51,642] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step56 is about to be saved!
[2024-08-09 00:21:51,672] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/global_step56/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:21:51,672] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/global_step56/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:21:51,686] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/global_step56/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-09 00:21:51,693] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/global_step56/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-09 00:22:11,079] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/global_step56/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:22:11,080] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56/global_step56/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-09 00:22:11,753 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-50] due to args.save_total_limit
[2024-08-09 00:22:11,745] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step56 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.036, 'grad_norm': 0.3617600411232251, 'learning_rate': 2.4000000000000003e-06, 'epoch': 10.13}
 76%|███████████████████████████████████████████████████████████████████████████████▊                         | 57/75 [1:12:29<35:13, 117.40s/it]

 77%|█████████████████████████████████████████████████████████████████████████████████▏                       | 58/75 [1:14:02<31:09, 109.98s/it]


 80%|████████████████████████████████████████████████████████████████████████████████████                     | 60/75 [1:17:29<26:49, 107.27s/it]
{'loss': 0.0331, 'grad_norm': 0.4037682398936568, 'learning_rate': 2.0000000000000003e-06, 'epoch': 10.67}

 81%|█████████████████████████████████████████████████████████████████████████████████████▍                   | 61/75 [1:19:17<25:04, 107.47s/it][INFO|trainer.py:3478] 2024-08-09 00:31:51,610 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61
[INFO|configuration_utils.py:472] 2024-08-09 00:31:51,615 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/config.json
[INFO|configuration_utils.py:769] 2024-08-09 00:31:51,616 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-09 00:32:07,705 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-09 00:32:07,709 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:32:07,709 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/special_tokens_map.json
[2024-08-09 00:32:08,501] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step61 is about to be saved!
[2024-08-09 00:32:08,537] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/global_step61/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:32:08,537] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/global_step61/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:32:08,551] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/global_step61/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-09 00:32:08,601] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/global_step61/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-09 00:32:29,437] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/global_step61/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:32:29,438] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61/global_step61/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-09 00:32:30,321 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-56] due to args.save_total_limit
[2024-08-09 00:32:30,313] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step61 is ready now!
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.0241, 'grad_norm': 0.44270538628289163, 'learning_rate': 1.7333333333333336e-06, 'epoch': 11.02}
 83%|██████████████████████████████████████████████████████████████████████████████████████▊                  | 62/75 [1:22:02<27:00, 124.68s/it]
 84%|████████████████████████████████████████████████████████████████████████████████████████▏                | 63/75 [1:22:55<20:37, 103.12s/it]
 84%|████████████████████████████████████████████████████████████████████████████████████████▏                | 63/75 [1:22:55<20:37, 103.12s/it]
 85%|█████████████████████████████████████████████████████████████████████████████████████████▌               | 64/75 [1:24:41<19:06, 104.20s/it]
 87%|███████████████████████████████████████████████████████████████████████████████████████████              | 65/75 [1:26:14<16:47, 100.72s/it]
 87%|███████████████████████████████████████████████████████████████████████████████████████████              | 65/75 [1:26:14<16:47, 100.72s/it]
{'loss': 0.0322, 'grad_norm': 0.35397296638769443, 'learning_rate': 1.3333333333333334e-06, 'epoch': 11.56}
 88%|████████████████████████████████████████████████████████████████████████████████████████████▍            | 66/75 [1:27:54<15:05, 100.60s/it]
 88%|████████████████████████████████████████████████████████████████████████████████████████████▍            | 66/75 [1:27:54<15:05, 100.60s/it]
 89%|█████████████████████████████████████████████████████████████████████████████████████████████▊           | 67/75 [1:29:46<13:51, 103.90s/it]
[INFO|configuration_utils.py:769] 2024-08-09 00:41:38,206 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/generation_config.json38,202 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67
[INFO|configuration_utils.py:769] 2024-08-09 00:41:38,206 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/generation_config.json38,202 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67
[2024-08-09 00:41:54,662] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step67 is about to be saved!
[2024-08-09 00:41:54,697] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/global_step67/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:41:54,698] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/global_step67/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:41:54,711] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/global_step67/zero_pp_rank_0_mp_rank_00_model_states.pt.
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:41:53,818 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/special_tokens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:41:53,818 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/special_tokens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/model.safetensors.index.json.
[2024-08-09 00:42:15,638] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/global_step67/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:42:15,640] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/global_step67/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-09 00:42:15,934 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-61] due to args.save_total_limitens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67/model.safetensors.index.json.
  warnings.warn(ython3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(ython3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 91%|███████████████████████████████████████████████████████████████████████████████████████████████▏         | 68/75 [1:32:23<13:58, 119.74s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 91%|███████████████████████████████████████████████████████████████████████████████████████████████▏         | 68/75 [1:32:23<13:58, 119.74s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 92%|████████████████████████████████████████████████████████████████████████████████████████████████▌        | 69/75 [1:34:12<11:40, 116.72s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 92%|████████████████████████████████████████████████████████████████████████████████████████████████▌        | 69/75 [1:34:12<11:40, 116.72s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████       | 70/75 [1:35:42<09:02, 108.59s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████       | 70/75 [1:35:42<09:02, 108.59s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████▍     | 71/75 [1:37:14<06:54, 103.56s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████▍     | 71/75 [1:37:14<06:54, 103.56s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 72/75 [1:38:47<05:01, 100.51s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 73/75 [1:40:28<03:20, 100.48s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 73/75 [1:40:28<03:20, 100.48s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
[INFO|configuration_utils.py:769] 2024-08-09 00:51:54,040 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/generation_config.json54,036 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73ve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:52:08,909 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/special_tokens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/model.safetensors.index.json.eentrant=True. Refer to docs for more details on the differences between the two variants.
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:52:08,909 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/special_tokens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/model.safetensors.index.json.eentrant=True. Refer to docs for more details on the differences between the two variants.
[2024-08-09 00:52:09,737] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step73 is about to be saved!
[2024-08-09 00:52:09,776] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/global_step73/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:52:09,776] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/global_step73/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:52:09,790] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/global_step73/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-09 00:52:09,831] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/global_step73/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-09 00:52:31,689] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/global_step73/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:52:31,690] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/global_step73/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:3570] 2024-08-09 00:52:32,364 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-67] due to args.save_total_limitens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73/model.safetensors.index.json.eentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(ython3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 74/75 [1:42:30<01:46, 106.92s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 74/75 [1:42:30<01:46, 106.92s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [1:43:44<00:00, 97.13s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [1:43:44<00:00, 97.13s/it] passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
[INFO|configuration_utils.py:769] 2024-08-09 00:54:56,586 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/generation_config.json56,582 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75ve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
[INFO|configuration_utils.py:769] 2024-08-09 00:54:56,586 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/generation_config.json56,582 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75ve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
[2024-08-09 00:55:12,253] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step75 is about to be saved!
[2024-08-09 00:55:12,286] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:55:12,286] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:55:12,299] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/zero_pp_rank_0_mp_rank_00_model_states.pt.
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:55:11,550 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/special_tokens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/model.safetensors.index.json.eentrant=True. Refer to docs for more details on the differences between the two variants.
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:55:11,550 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/special_tokens_map.jsonmeters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/model.safetensors.index.json.eentrant=True. Refer to docs for more details on the differences between the two variants.
[2024-08-09 00:55:31,121] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:55:31,122] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-08-09 00:55:34,145] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step75 is ready now!
[INFO|trainer.py:3570] 2024-08-09 00:55:34,160 >> Deleting older checkpoint [/model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-73] due to args.save_total_limit
[INFO|trainer.py:3478] 2024-08-09 00:55:56,586 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75
[INFO|configuration_utils.py:472] 2024-08-09 00:55:56,590 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/config.json
[INFO|configuration_utils.py:769] 2024-08-09 00:55:56,591 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-09 00:56:33,640 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-09 00:56:33,641 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:56:33,641 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/special_tokens_map.json
[2024-08-09 00:56:34,328] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step75 is about to be saved!
[2024-08-09 00:56:34,364] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-08-09 00:56:34,364] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-08-09 00:56:34,382] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-08-09 00:56:34,437] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-08-09 00:57:50,650] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-08-09 00:57:50,655] [INFO] [engine.py:3478:_save_zero_checkpoint] zero checkpoint saved /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/checkpoint-75/global_step75/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[INFO|trainer.py:2383] 2024-08-09 00:57:53,474 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [1:46:55<00:00, 85.53s/it]
[2024-08-09 00:57:53,467] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step75 is ready now!
{'train_runtime': 6423.5455, 'train_samples_per_second': 2.102, 'train_steps_per_second': 0.012, 'train_loss': 0.32985178686678407, 'epoch': 13.33}
[INFO|trainer.py:3478] 2024-08-09 00:58:08,514 >> Saving model checkpoint to /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5
[INFO|configuration_utils.py:472] 2024-08-09 00:58:08,518 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/config.json
[INFO|configuration_utils.py:769] 2024-08-09 00:58:08,519 >> Configuration saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/generation_config.json
[INFO|modeling_utils.py:2698] 2024-08-09 00:58:30,099 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2574] 2024-08-09 00:58:30,100 >> tokenizer config file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2583] 2024-08-09 00:58:30,101 >> Special tokens file saved in /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/special_tokens_map.json
[INFO|trainer.py:3788] 2024-08-09 00:58:31,239 >>
***** Running Evaluation *****
[INFO|trainer.py:3790] 2024-08-09 00:58:31,239 >>   Num examples = 100
[INFO|trainer.py:3793] 2024-08-09 00:58:31,239 >>   Batch size = 1
***** train metrics *****
  epoch                    =    13.3333
  total_flos               =     8103GF
  train_loss               =     0.3299
  train_runtime            = 1:47:03.54
  train_samples_per_second =      2.102
  train_steps_per_second   =      0.012
Figure saved at: /model/output/Llama-2-7b-hf-refined_alpaca_1k_longestk-e15lr1e-5/training_loss.png
08/09/2024 00:58:31 - WARNING - llamafactory.extras.ploting - No metric eval_loss to plot.
















100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:47<00:00,  2.35s/it]
[INFO|modelcard.py:449] 2024-08-09 00:59:21,949 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
***** eval metrics *****
  epoch                   =    13.3333
  eval_loss               =     1.7769
  eval_runtime            = 0:00:50.70
  eval_samples_per_second =      1.972
  eval_steps_per_second   =      0.394